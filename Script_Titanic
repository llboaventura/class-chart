#Class-chart

## Call Dataset and Choose the Classifier 
library(titanic)
varResp = 'Survived'
Medidas = function(mc){
  PE = (sum(mc[1,])*sum(mc[,1])+sum(mc[2,])*sum(mc[,2])+
          sum(mc[3,])*sum(mc[,3])+sum(mc[4,])*sum(mc[,4]))/((sum(mc[1,])+sum(mc[2,])+sum(mc[3,])+sum(mc[4,]))^2)
  PA = sum(diag(mc))/(sum(mc[1,])+sum(mc[2,])+sum(mc[3,])+sum(mc[4,]))
  Kappa = (PA-PE)/(1-PE)
  return(list(Kappa = Kappa))
}
formula = as.formula(paste(varResp, '~ .')) 

FormFac = function(formula){
  aux = as.character(formula)[2]
  return(as.formula(paste('factor(',aux, ')', '~ .')))
}
AuxSaida = function(pred, teste, formula, alg){
  ind = which(colnames(teste) == as.character(formula)[2])
  mc = matrix(NA,4,4)
  mc[1,1] = sum(teste[, ind]==0 & pred ==0)
  mc[1,2] = sum(teste[, ind]==1 & pred ==0)
  mc[1,3] = sum(teste[, ind]==2 & pred ==0)
  mc[1,4] = sum(teste[, ind]==3 & pred ==0)
  mc[2,1] = sum(teste[, ind]==0 & pred ==1)
  mc[2,2] = sum(teste[, ind]==1 & pred ==1)
  mc[2,3] = sum(teste[, ind]==2 & pred ==1)
  mc[2,4] = sum(teste[, ind]==3 & pred ==1)
  mc[3,1] = sum(teste[, ind]==0 & pred ==2)
  mc[3,2] = sum(teste[, ind]==1 & pred ==2)
  mc[3,3] = sum(teste[, ind]==2 & pred ==2)
  mc[3,4] = sum(teste[, ind]==3 & pred ==2)
  mc[4,1] = sum(teste[, ind]==0 & pred ==3)
  mc[4,2] = sum(teste[, ind]==1 & pred ==3)
  mc[4,3] = sum(teste[, ind]==2 & pred ==3)
  mc[4,4] = sum(teste[, ind]==3 & pred ==3)
  rs = Medidas(mc)
  rs[['Classificador']] = alg    
  return(do.call(data.frame, rs))  
}
Holdout = function(dados, p = 0.7){
  n_treino = ceiling(dim(dados)[1]*p)
  ind = c(rep('treino', n_treino), rep('teste', dim(dados)[1] - n_treino) )
  ind = sample(ind)
  treino = dados[ind == 'treino', ]
  teste  = dados[ind == 'teste' , ]
  return(list(treino = treino, teste = teste))
}
ValidCruzada = function(cls, dados, formula, kfolds = 10, ...){
  library(dismo)
  id = kfold(1:nrow(dados), kfolds)
  vcs = data.frame()
  for(i in 1:kfolds){
    treino = dados[id != i, ]
    teste = dados[id == i, ]
    kcls = cls(treino, teste, formula) 
    vcs = rbind(vcs, kcls)
  }
  vcs = vcs[, c(ncol(vcs), 1:(ncol(vcs) - 1))]
  avg = aggregate(. ~ Classificador, data = vcs, FUN = mean)
  std = aggregate(. ~ Classificador, data = vcs, FUN = sd)
  return(list(Media = avg, Desvio = avg, Modelos = vcs))
}


ValidCruzadarep = function(cls, dados, formula, kfolds = 5, reps = 10){
  x = data.frame()
  for(i in 1:reps) x = rbind(x, ValidCruzada(cls, dados, formula, kfolds)$Media) 
  avg = aggregate(. ~ Classificador, data = x, FUN = mean)### valor guardado que entra no gráfico da figura 5.3
  std = aggregate(. ~ Classificador, data = x, FUN = sd)
  return(list("Media Global"= avg, "Erro Padrão Validação Cruzada" = std, Modelos = x))
}


Arvore = function(treino, teste, formula){
  library(rpart) 
  cls = rpart(formula, data = data.frame(treino), method = 'class')
  pred = predict(cls, newdata = data.frame(teste), type = 'class')
  return(pred)
}

medArvore = function(treino, teste, formula){ 
  alg = 'Árvore de Decisão' 
  pred = Arvore(treino, teste, formula)
  return(AuxSaida(pred, teste, formula, alg))
}

dados = titanic_train[,c("Pclass","Survived","Sex","Age","SibSp",
                         "Embarked","Parch")]

ValidCruzadarep(medArvore, dados, formula, kfolds = 5, reps = 10)

### Phase I.1

######################################################################################
Medidas = function(pred){
  proporcoes = table(pred)/sum(table(pred))
  prop.0 = proporcoes[[1]]
  prop.1 = proporcoes[[2]]
  
  return(list("Prop 0"= prop.0, "Prop 1"=prop.1))
}
AuxSaida = function(pred, teste, formula, alg){
  rs = Medidas(pred)
  rs[['Classificador']] = alg    
  return(do.call(data.frame, rs))  
}
J.k.f = function(dados,cls, formula,...){
  vcs = data.frame()
  n = nrow(dados)
  for (j in 1:n){
    reamostra.jack = dados[-j,]
    treino = reamostra.jack
    teste  = reamostra.jack
    kcls = cls(treino, teste, formula) 
    vcs = rbind(vcs, kcls)
  }
  vcs = vcs[, c(ncol(vcs), 1:(ncol(vcs) - 1))]
  avg = aggregate(. ~ Classificador, data = vcs, FUN = mean)
  bvg = aggregate(. ~ Classificador, data = vcs, FUN = median)
  std = aggregate(. ~ Classificador, data = vcs, FUN = sd)
  return(list("Média" = avg, "Desvio" = std, Mediana= bvg, saidas = vcs))
}


LIMITES.DE.CONTROLE = J.k.f(dados,medArvore,formula)
LC.0 =  LIMITES.DE.CONTROLE$Média[[2]]
LC.1 =  LIMITES.DE.CONTROLE$Média[[3]]
s.0 =  LIMITES.DE.CONTROLE$Desvio[[2]]
s.1 =  LIMITES.DE.CONTROLE$Desvio[[3]]
LSC.0 = LC.0 + 3*s.0
LSC.1 = LC.1 + 3*s.1
LIC.0 = LC.0 - 3*s.0
LIC.1 = LC.1 - 3*s.1
lim.0 = paste0('[',round(LIC.0,3) ,';',round(LC.0,3) ,';',round(LSC.0,3) ,']')
lim.1 = paste0('[',round(LIC.1,3) ,';',round(LC.1,3) ,';',round(LSC.1,3) ,']')


########## PHASE I.2

TUNAGEM = function(cls, alpha,dados){
  rep = 10
  contador = 1
  Gamma = 1
  Gammas = data.frame()
  ARL0s = data.frame()
  NOMINAL= 0
  n = nrow(dados)
  MATRIZ.DE.ERROS = data.frame()
  reamostra = data.frame(matrix(NA,nrow = n*0.7,ncol = length(dados)))
  for (j in 1:rep) {
    NOMINAL= 0
    Gamma.corrigido = Gamma
    while (NOMINAL>(1/(alpha/2)) | NOMINAL <( 1/alpha)) { 
      erros= c(rep(NA,nrow(dados)))
      for (k in 1:nrow(dados)) {
        Holdout.reamostra = function(dados, p = 0.7){
          n_treino = ceiling(dim(dados)[1]*p)
          ind = c(rep('reamostra', n_treino), rep('descartada', dim(dados)[1] - n_treino) )
          ind = sample(ind)
          reamostra = dados[ind == 'reamostra', ]
          descarte  = dados[ind == 'descartada' , ]
          return(reamostra = reamostra)
        }
        reamostra = Holdout.reamostra(dados)
        pred = cls(reamostra,reamostra,formula)
        pred$Prop.0
        pred$Prop.1
        pred$Prop.2
        pred$Prop.3
        erros[k] = ifelse(LIC.0 > pred$Prop.0 | pred$Prop.0 > LSC.0  |
                            LIC.1 > pred$Prop.1 | pred$Prop.1 > LSC.1 , 1,0)
        
      }
      prop.dos.erros = sum(erros)/n
      MATRIZ.DE.ERROS = rbind(erros,MATRIZ.DE.ERROS)
      NOMINAL= 1/prop.dos.erros
      Gamma.corrigido= ifelse((NOMINAL > (1/(alpha/2))),Gamma.corrigido- 0.5,  
                              ifelse((NOMINAL < (1/(alpha))),Gamma.corrigido+ 0.5,Gamma.corrigido))
      #################################################################
      
      LSC.0 = LC.0 + 3*Gamma.corrigido*s.0
      LSC.1 = LC.1 + 3*Gamma.corrigido*s.1
      LIC.0 = LC.0 - 3*Gamma.corrigido*s.0
      LIC.1 = LC.1 - 3*Gamma.corrigido*s.1
      
      
      
      contador= contador+1
      ARL0s= rbind(NOMINAL,ARL0s)
      A= paste(contador,"-ésima iteração", "com Gamma =", 
               Gamma.corrigido, NOMINAL)
      print(A)
    }
    Gammas = rbind(Gamma.corrigido,Gammas)
  }
  return(list("ARL ZERO" = ARL0s, "Parâmetros de Tunagem Gammas" =  
                Gammas, 
              "Número de iterações"= contador,
              "Gammas"=Gammas, "Matriz de Erros"= MATRIZ.DE.ERROS))
}

simulacao = TUNAGEM(medArvore, alpha=0.0027,dados) 
Gamma.c = median(simulacao$Gammas[[1]])
LSC.0 = LC.0 + 3*Gamma.c*s.0
LSC.1 = LC.1 + 3*Gamma.c*s.1     
LIC.0 = LC.0 - 3*Gamma.c*s.0
LIC.1 = LC.1 - 3*Gamma.c*s.1
lim.0.c = paste0('[',round(LIC.0,3) ,';',round(LC.0,3) ,';',round(LSC.0,3) ,']')
lim.1.c = paste0('[',round(LIC.1,3) ,';',round(LC.1,3) ,';',round(LSC.1,3) ,']')


#Multinominal Chart
p_barra = (sum(dados$Survived == 0)*(sum(dados$Survived == 0)/length(dados$Survived)) +
  sum(dados$Survived == 1)*(sum(dados$Survived == 1)/length(dados$Survived)) ) /
  length(dados$Survived)

LSC = p_barra + 3*sqrt(((sum(dados$Survived == 0)*(sum(dados$Survived == 0)/length(dados$Survived))*
                      (sum(dados$Survived == 1)/length(dados$Survived))))/length(dados$Survived))

LIC = p_barra + 3*sqrt(((sum(dados$Survived == 0)*(sum(dados$Survived == 0)/length(dados$Survived))*
                           (sum(dados$Survived == 1)/length(dados$Survived))))/length(dados$Survived))
